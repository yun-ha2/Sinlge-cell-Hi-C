# Preprocessing

This directory contains dataset-specific preprocessing pipelines for
single-cell Hi-C (scHi-C) data.

The goal of preprocessing is to convert heterogeneous raw scHi-C formats
(e.g. Lee, Nagano) into a unified, chromosome-wise sparse matrix
representation, and to further interpret these representations as graph
structures suitable for graph-based learning.

Dataset-specific differences are handled only at this stage, ensuring that
all downstream components operate on the same data representation.

---

## Supported Datasets

- **Lee et al.**
  - Input format: multi-resolution Cooler files (`.mcool`)
  - Genome metadata and binning are handled internally by `cooler`

- **Nagano et al.**
  - Input format: schic2 per-cell interaction outputs
  - Requires external chromosome size information for binning

---

## Output Format

### 1. Chromosome-wise contact matrices (`.npz`)
All preprocessing pipelines produce compressed `.npz` files with the same structure:

```text
cell_id.npz
 ├─ chr1 → scipy.sparse.csr_matrix
 ├─ chr2 → scipy.sparse.csr_matrix
 ├─ ...
```
### 2.scHi-C graph inputs (`.pt`)
This step converts the standardized scHi-C representations stored in .npz
files into graph inputs suitable for graph neural networks.

Graph inputs are constructed by combining chromosome-wise contact matrices
and node features:

#### Inputs
```text
contact_dir/<cell_id>.npz   # chromosome-wise contact matrices
feature_dir/<cell_id>.npz   # chromosome-wise node features
```

#### Output
```text
<cell_id>_<chrom>.pt
```


Each file corresponds to a single chromosome from one cell and contains a
PyTorch Geometric graph:
```text
Data(
  x,          # node features
  edge_index, # sparse edge list
  edge_attr   # contact counts
)
```


### 3. Cell-level embeddings 

Cell-level embeddings are computed from the standardized per-cell contact matrices (`.npz`)
using a scHiCluster-style preprocessing (coverage normalization + sqrtVC) followed by PCA/SVD.
These embeddings are used as targets for the cosine alignment loss during model training.

#### Input

```text
contact_dir/<cell_id>.npz   # chromosome-wise contact matrices
```

#### Output
```text
cell_embeddings.npy   # (n_cells, d) PCA embedding vectors
cell_names.txt        # cell_id list aligned with rows in cell_embeddings.npy
```

---

## Usage

Preprocessing is executed via CLI scripts located in the scripts/ directory:

```text
python scripts/preprocess_lee.py --help
python scripts/preprocess_nagano.py --help
```
Refer to individual scripts for dataset-specific options.

---

## Genome annotation files

The Nagano preprocessing pipeline requires the following external genome files:

- `GATC.fends`  
  Restriction fragment annotation file used by schic2 to map fragment IDs
  to genomic coordinates.

- `mm9.chrom.sizes`  
  Chromosome size file for the mm9 genome assembly.

These files are not included in this repository and should be obtained
from the original schic2 distribution or generated by the user.

---

## DNA bin sequence extraction (optional)

Some downstream components (e.g., DNA embedding extraction) require
genome-wide DNA sequences at a fixed bin size. The utility
src/preprocessing/dna_bins.py generates per-bin sequences from a reference
FASTA and saves them as a JSON list.

The output chromosome names are normalized to UCSC-style (chr*) to ensure
consistent downstream processing across genome builds and FASTA header styles.

### Output schema

```text
[
  {"chrom": "chr1", "bin": 1, "sequence": "ACGT..."},
  {"chrom": "chr1", "bin": 2, "sequence": "TTGA..."},
  ...
]
```

### Usage

```text
python scripts/make_dna_bins.py --help
```
Examples:
```text
# hg19 (500kb bins)
python scripts/make_dna_bins.py \
  --fasta /path/to/hg19.fa \
  --out /path/to/hg19_bins_500kb_list.json \
  --bin_size 500000 \
  --chrom_style hg19

# mm9 (10kb bins)
python scripts/make_dna_bins.py \
  --fasta /path/to/mm9.fa \
  --out /path/to/mm9_bins_10kb_list.json \
  --bin_size 10000 \
  --chrom_style mm9

```
---

## Note

Dataset-specific differences are intentionally handled only at the
preprocessing stage. All downstream components operate on the same
data representation.
